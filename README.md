# ğŸš€ Customer Churn Prediction and Retention for FinTech

![Python](https://img.shields.io/badge/Python-3.11-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-0.100%2B-green)
![Streamlit](https://img.shields.io/badge/Streamlit-Latest-red)
![MLflow](https://img.shields.io/badge/MLflow-Tracking-orange)
![License](https://img.shields.io/badge/License-MIT-yellow)

Complete churn prediction system for financial institutions, including REST API, real-time monitoring dashboard, automatic drift detection, and model explainability using SHAP.

## ğŸ¯ Project Description

Data Science project developed during a job simulation at **NoCountry**, implementing a complete Machine Learning pipeline in production that covers from training to continuous model monitoring.

### Main Components

- **ğŸ¤– ML Model**: Logistic Regression optimized to maximize Recall (76%) in churn detection
- **ğŸ“Œ REST API**: FastAPI endpoint for real-time predictions with automatic database logging
- **ğŸ“Š Interactive Dashboard**: Streamlit application with KPIs, visualizations, and SHAP analysis
- **ğŸ¨ Gradio Interface**: User-friendly UI for individual predictions
- **ğŸ“ˆ Drift Monitoring**: Automatic system with Evidently to detect model degradation
- **ğŸ”„ CI/CD**: Automated pipelines with GitHub Actions for deployment and monitoring

## ğŸŒ Live Demos

| Component | URL | Description |
|-----------|-----|-------------|
| **API** | [Hugging Face Space](https://Itrs-api-churn.hf.space) | Endpoint for predictions `/prediccion` |
| **Dashboard** | [Streamlit Cloud](https://dashboard-churn-prediction.streamlit.app) | Real-time monitoring and analysis |
| **Gradio App** | [Hugging Face Space](https://huggingface.co/spaces/Itrs/ui-churn-prediction) | Interactive interface for predictions |
| **Drift Report** | [GitHub Pages](https://itrosellosignoris.github.io/Prediccion-de-Churn-y-Retencion-de-Clientes-para-FinTech/drift_report.html) | Automatic data drift analysis |

## ğŸ› ï¸ Tech Stack

### Machine Learning & Data Science
- **Python 3.11** - Main language
- **Scikit-learn 1.6.1** - Preprocessing, modeling, and metrics
- **imbalanced-learn (SMOTE)** - Handling imbalanced classes
- **SHAP** - Model explainability (Linear Explainer)
- **MLflow** - Experiment tracking and model versioning
- **Evidently** - Data drift monitoring

### Backend & API
- **FastAPI** - REST API framework
- **Uvicorn** - High-performance ASGI server
- **Pydantic** - Data validation and schemas
- **psycopg2** - PostgreSQL connector

### Frontend & Visualization
- **Streamlit** - Interactive monitoring dashboard
- **Gradio** - User interface for predictions
- **Plotly** - Interactive charts
- **Matplotlib/Seaborn** - Static visualizations

### Database & Storage
- **Supabase (PostgreSQL)** - Database for storing predictions
- **GitHub Pages** - Hosting for drift reports

### DevOps & CI/CD
- **Docker** - Application containerization
- **GitHub Actions** - Workflow automation:
  - Automatic synchronization with Hugging Face
  - Daily drift report generation (cron: 8 AM UTC)
  - Automatic production deployment

## ğŸ“ Project Structure

```
Prediccion-de-Churn-y-Retencion-de-Clientes-para-FinTech/
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ sync_to_hub.yml          # Sync with Hugging Face
â”‚       â””â”€â”€ run_monitor.yml          # Drift report generation
â”‚
â”œâ”€â”€ deployment/
â”‚   â”œâ”€â”€ api.py                       # FastAPI application
â”‚   â”œâ”€â”€ dashboard.py                 # Streamlit dashboard
â”‚   â”œâ”€â”€ drift_monitor.py             # Evidently monitoring script
â”‚   â”œâ”€â”€ requirements_monitor.txt     # Deps for drift monitoring
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ historical_data.csv      # Reference data
â”‚   â”‚   â””â”€â”€ X_train_final_linear.csv # Data for SHAP
â”‚   â”œâ”€â”€ shap_plots/
â”‚   â”‚   â””â”€â”€ shap_summary.png         # Global feature importance
â”‚   â”œâ”€â”€ gradio_app/
â”‚   â”‚   â”œâ”€â”€ app.py                   # Gradio application
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â””â”€â”€ .streamlit/
â”‚       â””â”€â”€ config.toml              # Streamlit configuration
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ datasets/                 
â”‚   â”‚   â”œâ”€â”€ adapted_data                      # Intermediate data after initial transformations
â”‚   â”‚   â”‚   â””â”€â”€ Churn_Modelling_adapted.csv   # Dataset with feature engineering and type conversions
â”‚   â”‚   â”œâ”€â”€ processed_data                    # Final clean data ready for modeling
â”‚   â”‚   â”‚   â””â”€â”€ cleaned_data.csv              # Preprocessed dataset
â”‚   â”‚   â””â”€â”€ raw_data                          # Original unmodified data
â”‚   â”‚   â”‚   â””â”€â”€ Churn_Modelling.csv           # Raw dataset from source
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ best_model.pkl           # Logistic Regression model
â”‚   â”‚   â””â”€â”€ scaler.pkl               # StandardScaler fitted
â”‚   â”œâ”€â”€ notebooks/
â”‚   â”‚   â”œâ”€â”€ data_adaptation.ipynb     # Complete data adaptation notebook
â”‚   â”‚   â”œâ”€â”€ eda.ipynb                 # Complete eda notebook
â”‚   â”‚   â”œâ”€â”€ data_preparation.ipynb    # Complete data preparation notebook
â”‚   â”‚   â””â”€â”€ training.ipynb            # Complete training notebook
â”‚   â””â”€â”€ ohe_categories_without_exited.pickle  # OHE categories
â”‚
â”œâ”€â”€ public/                           # GitHub Pages (auto-generated)
â”‚   â”œâ”€â”€ drift_report.html             # Evidently report
â”‚   â””â”€â”€ drift_status.json             # Drift status (JSON)
â”‚
â”œâ”€â”€ Dockerfile                        # Container definition
â”œâ”€â”€ requirements.txt                  # Main dependencies
â””â”€â”€ README.md
```

## ğŸš€ Installation and Usage

### Prerequisites

- Python 3.11
- Docker (optional)
- Supabase account (for database)
- Hugging Face account (for deployment)

### Local Installation

1. **Clone the repository**
```bash
git clone https://github.com/ITRoselloSignoris/Prediccion-de-Churn-y-Retencion-de-Clientes-para-FinTech.git
cd Prediccion-de-Churn-y-Retencion-de-Clientes-para-FinTech
```

2. **Create virtual environment**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Configure environment variables**
```bash
export SUPABASE_CONNECTION_STRING="postgresql://user:password@host:port/database"
```

### ğŸ“Œ Run the API

```bash
uvicorn deployment.api:app --host 0.0.0.0 --port 7860 --reload
```

The API will be available at `http://localhost:7860`

**Interactive documentation:** `http://localhost:7860/docs`

### ğŸ“Š Run the Dashboard

```bash
streamlit run deployment/dashboard.py
```

The dashboard will be available at `http://localhost:8501`

### ğŸ¨ Run the Gradio App

```bash
cd deployment/gradio_app
python app.py
```

### ğŸ³ Deployment with Docker

```bash
# Build the image
docker build -t churn-api .

# Run the container
docker run -p 7860:7860 -e SUPABASE_CONNECTION_STRING="your_connection_string" churn-api
```

## ğŸ“Š API Usage

### Main Endpoint: `/prediccion`

**Method:** `POST`

**Request Body:**
```json
{
  "CreditScore": 650,
  "Age": 35,
  "Tenure": 5,
  "Balance": 100000.50,
  "HasCrCard": true,
  "IsActiveMember": true,
  "EstimatedSalary": 75000.00,
  "Geography": "Spain",
  "Gender": "Female",
  "NumOfProducts": 2
}
```

**Response:**
```json
{
  "PredicciÃ³n de Churn": "No",
  "Probabilidad de Churn": 0.23
}
```

### System Features

- âš¡ **Average latency**: < 100ms per prediction
- ğŸ’¾ **Automatic storage**: All predictions are logged to Supabase
- ğŸ“ˆ **Tracking**: Model version and metrics via MLflow
- ğŸ¯ **Custom threshold**: 0.6 (configurable)

## ğŸ§  Model Training Process

### Data Preparation

The model was trained using the `cleaned_data.csv` dataset with the following techniques:

1. **Imbalance Analysis**: 
   - Target variable `Exited`: ~80% no-churn, 20% churn
   - Split: 80/20 train/test with `random_state=42`

2. **Imbalance Handling**:
   - Technique: **SMOTE** (Synthetic Minority Over-sampling Technique)
   - Applied only on training data
   - Two balanced sets generated:
     - `X_train_final`: Unscaled (for tree models)
     - `X_train_final_linear`: Scaled with StandardScaler (for Logistic Regression)

3. **Preprocessing**:
   - **StandardScaler**: Normalization of numerical features
   - **One-Hot Encoding**: Categorical variables (Geography, Gender, NumOfProducts)
   - **17 final features** after encoding

### Experimentation and Model Selection

**3 algorithms** were evaluated with hyperparameter optimization focused on **maximizing Recall**:

| Model | Tuning Technique | Recall (Test) | F1-Score | ROC AUC |
|-------|------------------|---------------|----------|---------|
| **RandomForestClassifier** | RandomizedSearchCV (20 iter) + GridSearchCV | 0.66 | 0.57 | 0.83 |
| **XGBClassifier** | RandomizedSearchCV (15 iter) + GridSearchCV | 0.55 | 0.59 | 0.84 |
| **LogisticRegression** â­ | RandomizedSearchCV (30 iter) + GridSearchCV | **0.76** | 0.56 | 0.84 |

### Final Selected Model

**ğŸ† Logistic Regression with `class_weight='balanced'`**

**Selection Justification:**
- âœ… **Highest Recall (0.76)**: Detects 76% of customers who actually churn
- âœ… **Interpretability**: Linear coefficients easy to explain with SHAP
- âœ… **Balanced performance**: ROC AUC of 0.84 indicates excellent discriminative capacity
- âœ… **Efficiency**: Fast predictions, ideal for production

### Generated Artifacts

1. **`best_model.pkl`**: Trained Logistic Regression model
2. **`scaler.pkl`**: StandardScaler fitted with training data
3. **`ohe_categories_without_exited.pickle`**: Categories for One-Hot Encoding
4. **`shap_summary.png`**: Global feature importance plot
5. **MLflow Artifacts**: Complete record of experiments, metrics, and parameters

## ğŸ“ˆ Model and Results

### Model Metrics

| Metric | Value | Interpretation |
|--------|-------|----------------|
| **Recall** | 76.0% | Detects 76% of actual churns |
| **Precision** | 47.0% | 47% of positive predictions are correct |
| **F1-Score** | 56.0% | Balance between Precision and Recall |
| **ROC AUC** | 84.0% | Excellent discriminative capacity |

**Note on Recall:** The model was optimized to **maximize Recall**, prioritizing the detection of all possible churn cases (minimizing false negatives). This is critical in contexts where the cost of not detecting a churn is greater than having false alarms.

### Most Important Features (SHAP)

Based on global SHAP analysis, the features with the greatest impact are:

1. **Age** - Customer age (older customers have higher risk)
2. **NumOfProducts** - Number of contracted products (3 or 4 products increases risk)
3. **IsActiveMember** - Activity status (inactive customers more prone to churn)
4. **Balance** - Account balance (extreme balances affect churn)
5. **Geography** - Geographic location (regional differences in behavior)

### Production Pipeline

```
Input Data 
    â†“
[One-Hot Encoding] â†’ Geography (3), Gender (2), NumOfProducts (4)
    â†“
[StandardScaler] â†’ Normalization of numerical features
    â†“
[Logistic Regression] â†’ Churn probability [0-1]
    â†“
[Threshold 0.6] â†’ Final classification (Churn / No Churn)
```

## ğŸ”„ CI/CD and Automation

### GitHub Actions Workflows

#### 1. **Sync to Hugging Face** (`sync_to_hub.yml`)
- **Trigger**: Push to `main` branch or manual execution
- **Action**: Automatically synchronizes code with Hugging Face Spaces
- **Result**: API and Gradio app always up-to-date

#### 2. **Generate Drift Report** (`run_monitor.yml`)
- **Triggers**: 
  - Push to `main`
  - Daily cron (8:00 AM UTC)
  - Manual execution
- **Actions**:
  1. Extracts last 5000 predictions from Supabase
  2. Compares with historical data using Evidently
  3. Generates interactive HTML report
  4. Creates JSON file with drift status
  5. Publishes to GitHub Pages
- **Result**: Automatic model degradation monitoring

### Drift Monitoring

The system detects two types of drift:

- **Data Drift**: Changes in feature distributions
- **Target Drift**: Changes in prediction distributions

**Monitored features:** 16 variables (all model features)

The dashboard shows automatic alerts when drift is detected:
- ğŸš¨ Red alert: Drift detected
- âœ… Green indicator: No drift

## ğŸ“Š Monitoring Dashboard

The Streamlit dashboard includes 5 main tabs:

### 1. ğŸ“ˆ KPIs and Trends
- Total processed predictions
- Global churn risk percentage
- API average latency
- Hourly trend charts

### 2. ğŸ“Š Recent Distributions
- Histograms of numerical features
- Categorical variable distributions
- Visual analysis of latest data

### 3. ğŸ”¬ Drift Monitor
- Interactive Evidently report
- Current drift status
- Features with detected drift

### 4. ğŸ—ƒï¸ Filtered Customers
- Interactive table with recent predictions
- Filters by probability, geography, gender, etc.
- Customer selection for SHAP analysis

### 5. ğŸ•µï¸â€â™‚ï¸ Explainability (SHAP)
- Global feature importance
- Individual force plots
- Detailed waterfall plots
- Customer-specific interpretation

## ğŸ—„ï¸ Database

### Table: `predictions`

Supabase table structure:

| Column | Type | Description |
|--------|------|-------------|
| `id` | SERIAL | Auto-incremental ID |
| `timestamp` | TIMESTAMP | Prediction moment |
| `latency_ms` | FLOAT | Response time |
| `model_version` | VARCHAR | Used model version |
| `prediction` | INTEGER | Prediction (0/1) |
| `confidence` | FLOAT | Churn probability |
| `creditscore` | INTEGER | Credit score |
| `age` | INTEGER | Customer age |
| `tenure` | INTEGER | Tenure |
| `balance` | FLOAT | Account balance |
| `hascrcard` | BOOLEAN | Has credit card |
| `isactivemember` | BOOLEAN | Active member |
| `estimatedsalary` | FLOAT | Estimated salary |
| `geography_*` | BOOLEAN | Geography OHE variables |
| `gender_*` | BOOLEAN | Gender OHE variables |
| `numofproducts_*` | BOOLEAN | Products OHE variables |

## ğŸ”§ Maintenance and Monitoring

### Model Retraining

If drift or metric degradation is detected:

1. **Collect New Data**:
   - Export recent predictions from Supabase
   - Label actual churn cases (if available)

2. **Retrain**:
   - Run `notebooks/training.ipynb` with updated data
   - Apply SMOTE and StandardScaler
   - Optimize for Recall with RandomizedSearchCV/GridSearchCV
   - Compare with baseline: Recall â‰¥ 0.75

3. **Validate**:
   - Verify metrics on test set
   - Compare ROC AUC with current model
   - Generate new SHAP analyses

4. **Deploy**:
   - Save artifacts in `src/model/`
   - Register in MLflow with new version
   - Push to `main` â†’ Automatic deploy via GitHub Actions
   - Update `historical_data.csv` if necessary

### Drift Review

1. Check dashboard (automatic alert if drift exists)
2. Review complete report on GitHub Pages
3. If drift confirmed:
   - Update reference data
   - Consider retraining

### Log Monitoring

- **API**: Logs in Hugging Face Spaces console
- **Dashboard**: Logs in Streamlit Cloud
- **Drift**: Logs in GitHub Actions runs

## ğŸ” Secrets Configuration

### GitHub Actions
- `HF_TOKEN`: Hugging Face token for deployment
- `SUPABASE_CONNECTION_STRING`: Database connection

### Streamlit Cloud
- `SUPABASE_CONNECTION_STRING`: Database connection

## ğŸ‘¨â€ğŸ’» Author

**IÃ±aki TomÃ¡s Rosello Signoris**

Project developed during **NoCountry** job simulation

- GitHub: [@ITRoselloSignoris](https://github.com/ITRoselloSignoris)
- LinkedIn: [IÃ±aki Rosello Signoris](https://www.linkedin.com/in/i%C3%B1akirosellosignoris/)

## ğŸ“„ License

This project is under the MIT License - see the [LICENSE](LICENSE) file for more details.

## ğŸ™ Acknowledgments

- **NoCountry** for the opportunity to develop this project
---

## ğŸ“ Key Learnings

This project demonstrates the complete implementation of an ML system in production:

âœ… **MLOps**: Versioning with MLflow, CI/CD with GitHub Actions  
âœ… **Experimentation**: Rigorous comparison of 3 algorithms with hyperparameter optimization  
âœ… **Imbalance Handling**: SMOTE for class balancing  
âœ… **Metric Optimization**: Prioritization of Recall over Accuracy  
âœ… **Monitoring**: Automatic drift detection with Evidently  
âœ… **Productization**: REST API + Dashboard + User interface  
âœ… **Explainability**: SHAP for decision transparency  
âœ… **Scalability**: Docker, cloud services, serverless database  
âœ… **Automation**: Daily reports, continuous synchronization  

---

## ğŸ“š Additional Resources

- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Streamlit Documentation](https://docs.streamlit.io/)
- [SHAP Documentation](https://shap.readthedocs.io/)
- [Evidently AI](https://docs.evidentlyai.com/)
- [MLflow Tracking](https://mlflow.org/docs/latest/tracking.html)
- [imbalanced-learn (SMOTE)](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html)

---

â­ï¸ If you found this project useful, don't forget to give it a star on GitHub!


**Project Status:** âœ… Active and in production
